{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import json\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# cristian path \n",
    "base_dir = '/home/csalitre/school/ecgr-5106/final-project/' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = base_dir + '/semantic-segmentation/data/train/_annotations.coco.json'\n",
    "file_path_valid = base_dir + '/semantic-segmentation/data/valid/_annotations.coco.json'   \n",
    "file_paht_test = base_dir + '/semantic-segmentation/data/test/_annotations.coco.json'\n",
    "\n",
    "# Doc file JSON\n",
    "with open(file_path_train, 'r') as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "with open(file_path_valid, 'r') as file:\n",
    "    data_valid = json.load(file)\n",
    "\n",
    "with open(file_paht_test, 'r') as file:\n",
    "    data_test = json.load(file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_train = data_train['categories']\n",
    "images_train = data_train['images']\n",
    "annotations_train = data_train['annotations']\n",
    "\n",
    "categories_valid = data_valid['categories']\n",
    "images_valid = data_valid['images']\n",
    "annotations_valid = data_valid['annotations']\n",
    "\n",
    "categories_test = data_test['categories']\n",
    "images_test = data_test['images']\n",
    "annotations_test = data_test['annotations'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maskGt(segmentations, input_image):\n",
    "    \"\"\" \n",
    "    Create a mask from a list of segmentations.\n",
    "\n",
    "    Args:\n",
    "        segmentations: A list of segmentation polygons.\n",
    "        input_image: The input image.\n",
    "\n",
    "    Returns:\n",
    "        A binary mask as a NumPy array.\n",
    "    \"\"\"\n",
    "    mask = np.zeros((input_image.height, input_image.width), dtype=np.uint8)\n",
    "    \n",
    "    for seg in segmentations:\n",
    "        poly = np.array(seg).reshape((-1, 2))\n",
    "        img_poly = Polygon(poly)\n",
    "        x, y = np.meshgrid(np.arange(input_image.width), np.arange(input_image.height))\n",
    "        x, y = x.flatten(), y.flatten()\n",
    "        points = np.vstack((x, y)).T\n",
    "\n",
    "        path = img_poly.get_path()\n",
    "        grid = path.contains_points(points)\n",
    "        grid = grid.reshape((input_image.height, input_image.width))\n",
    "        mask[grid] = 1\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_masks(image, mask_gt, mask_pred_classic, mask_pred_finetune, figsize=(15, 15)):\n",
    "    \"\"\"\n",
    "    Visualizes two masks side-by-side, along with the original image.\n",
    "\n",
    "    Args:\n",
    "        image: The original image.\n",
    "        mask_gt: The ground truth mask.\n",
    "        mask_gd: The predicted mask.\n",
    "        figsize: The size of the figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new figure with three subplots.\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    # Plot the ground truth mask on the second subplot.\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].imshow(mask_gt, alpha =0.5)\n",
    "    axes[0].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    # Plot the predicted mask on the third subplot.\n",
    "    axes[1].imshow(image)\n",
    "    axes[1].imshow(mask_pred_classic, alpha =0.5)\n",
    "    axes[1].set_title(\"Predicted Mask Classic\")\n",
    "    # Plot the predicted mask on the third subplot.\n",
    "    axes[2].imshow(image)\n",
    "    axes[2].imshow(mask_pred_finetune, alpha =0.5)\n",
    "    axes[2].set_title(\"Predicted Mask Finetune\")\n",
    "\n",
    "    # Show the figure.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Debug opening images : encountering No file found for .jpg\\nfor image in images_train:\\n    image_path = os.path.join(file_path_train + image[\\'file_name\\'])\\n    try: \\n        with Image.open(image_path) as image_file:\\n            # Process the image\\n            pass \\n\\n    except FileNotFoundError as e:\\n        print(f\"Error opening image: {image_path}\")\\n        print(e)\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_train = base_dir + '/semantic-segmentation/data/train/'\n",
    "file_path_valid = base_dir + '/semantic-segmentation/data/valid/'\n",
    "file_path_test = base_dir + '/semantic-segmentation/data/test/'\n",
    "\n",
    "\"\"\"\n",
    "# Debug opening images : encountering No file found for .jpg\n",
    "for image in images_train:\n",
    "    image_path = os.path.join(file_path_train + image['file_name'])\n",
    "    try: \n",
    "        with Image.open(image_path) as image_file:\n",
    "            # Process the image\n",
    "            pass \n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error opening image: {image_path}\")\n",
    "        print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimgs_train = []\\nfor image in images_train:\\n    imgs_train.append(Image.open(file_path_train + image['file_name']))\\n\\nmsks_train = []\\nfor i in range(len(imgs_train)):\\n    image_obj = imgs_train[i]\\n    mask = create_maskGt(annotations_train[i]['segmentation'], image_obj)\\n    msks_train.append(mask)\\n    \""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debugging purposes\n",
    "\"\"\"\n",
    "imgs_train = []\n",
    "for image in images_train:\n",
    "    imgs_train.append(Image.open(file_path_train + image['file_name']))\n",
    "\n",
    "msks_train = []\n",
    "for i in range(len(imgs_train)):\n",
    "    image_obj = imgs_train[i]\n",
    "    mask = create_maskGt(annotations_train[i]['segmentation'], image_obj)\n",
    "    msks_train.append(mask)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502\n",
      "1502\n",
      "429\n",
      "429\n",
      "215\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "imgs_train = []\n",
    "for image in images_train:\n",
    "    imgs_train.append(Image.open(file_path_train + image['file_name']))\n",
    "\n",
    "msks_train = []\n",
    "for i in range(len(imgs_train)): \n",
    "    image_obj = imgs_train[i]       \n",
    "    mask = create_maskGt(annotations_train[i]['segmentation'], image_obj)\n",
    "    msks_train.append(mask)\n",
    "\n",
    "imgs_val = []\n",
    "for image in images_valid:\n",
    "    imgs_val.append(Image.open(file_path_valid + image['file_name']))\n",
    "\n",
    "msks_val = []\n",
    "for i in range(len(imgs_val)):\n",
    "    image_obj = imgs_val[i]\n",
    "    mask = create_maskGt(annotations_valid[i]['segmentation'], image_obj)\n",
    "    msks_val.append(mask)\n",
    "\n",
    "imgs_test = []\n",
    "for image in images_test:\n",
    "    imgs_test.append(Image.open(file_path_test + image['file_name']))\n",
    "\n",
    "msks_test = []\n",
    "for i in range(len(imgs_test)):\n",
    "    image_obj = imgs_test[i]\n",
    "    mask = create_maskGt(annotations_test[i]['segmentation'], image_obj)\n",
    "    msks_test.append(mask)\n",
    "\n",
    "print(len(imgs_train))\n",
    "print(len(msks_train))\n",
    "print(len(imgs_val))\n",
    "print(len(msks_val))\n",
    "print(len(imgs_test))\n",
    "print(len(msks_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original image\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(imgs_train[0])\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the mask\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(msks_train[0], cmap='gray')\n",
    "plt.title('Masked Image')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
