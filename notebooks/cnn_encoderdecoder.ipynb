{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from matplotlib.patches import Polygon\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import random \n",
    "import matplotlib.patches as patches\n",
    "import skimage.draw \n",
    "import tifffile \n",
    "import shutil\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# cristian path \n",
    "base_dir = '/home/csalitre/school/ecgr-5106/final-project/' \n",
    "\n",
    "train_path = base_dir + 'semantic-segmentation/train2/' \n",
    "valid_path = base_dir + 'semantic-segmentation/valid2/'\n",
    "test_path = base_dir + 'semantic-segmentation/test2/'\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),  # Assuming grayscale images\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1))\n",
    "])\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets, smooth=1e-6):\n",
    "        # Compute intersection\n",
    "        intersection = torch.sum(logits * targets)\n",
    "        \n",
    "        # Compute Dice coefficient\n",
    "        dice_coefficient = (2. * intersection + smooth) / (\n",
    "            torch.sum(logits) + torch.sum(targets) + smooth\n",
    "        )\n",
    "        \n",
    "        # Compute Dice loss\n",
    "        dice_loss = 1.0 - dice_coefficient\n",
    "        \n",
    "        return dice_loss\n",
    "\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_folder = os.path.join(root_dir, \"images\")\n",
    "        self.mask_folder = os.path.join(root_dir, \"masks\")\n",
    "        self.image_files = sorted(os.listdir(self.image_folder))\n",
    "        self.mask_files = sorted(os.listdir(self.mask_folder))\n",
    "        self.transform = transform\n",
    "\n",
    "        # Print lengths of image_files and mask_files for debugging\n",
    "        print(f\"Length of image files: {len(self.image_files)}\")\n",
    "        print(f\"Length of mask files: {len(self.mask_files)}\")\n",
    "\n",
    "     # Check consistency of image and mask files\n",
    "        if len(self.image_files) != len(self.mask_files):\n",
    "            mismatched_file_index = len(self.image_files) if len(self.image_files) < len(self.mask_files) else len(self.mask_files)\n",
    "            print(f\"Mismatched files: {self.image_files[mismatched_file_index]}\")\n",
    "            raise ValueError(\"Number of images and masks do not match.\")\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        image_gray = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "        mask_name = self.mask_files[idx]\n",
    "        mask_path = os.path.join(self.mask_folder, mask_name)\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            # Apply transformations\n",
    "            image_gray = self.transform(image_gray)\n",
    "            mask = self.transform(mask)\n",
    "        return image_gray, mask\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = BrainDataset(train_path, transform=image_transform)\n",
    "valid_dataset = BrainDataset(valid_path, transform=image_transform)\n",
    "test_dataset = BrainDataset(test_path, transform=image_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define cnn encoder-decoder model\n",
    "class CNN_EncoderDecoder(nn.Module):\n",
    "    def __init__(self,in_chans=1, out_chans=64, sampling_factor=2):\n",
    "        super(CNN_EncoderDecoder, self).__init__()\n",
    "        # Define encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=sampling_factor),\n",
    "            nn.Conv2d(out_chans, out_chans * 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=sampling_factor))\n",
    "        \n",
    "        # Define decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(out_chans * 2 , out_chans, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(out_chans, in_chans, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(model, train_loader, valid_loader, num_epochs, learning_rate):\n",
    "    # Define loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "     \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train =0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # zero out the gradients\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            loss.backward() # back propagate the loss\n",
    "            optimizer.step()    # update the weights\n",
    "            train_loss += loss.item() # add the loss to the train loss\n",
    "\n",
    "            predicted = outputs > 0.5   # threshold the outputs to get the predicted masks\n",
    "            correct_train += (predicted == masks).sum().item()\n",
    "            total_train += masks.numel()\n",
    "\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in valid_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                predicted = outputs > 0.5\n",
    "                correct_valid += (predicted == masks).sum().item()\n",
    "                total_valid += masks.numel()\n",
    "\n",
    "        valid_accuracy = correct_valid / total_valid\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "              f\"Train loss: {train_loss/len(train_loader):.4f}, \"\n",
    "               f\"Train accuracy: {train_accuracy:.4f}, \"\n",
    "               f\"Validation loss: {valid_loss/len(valid_loader):.4f}, \"\n",
    "               f\"Validation accuracy: {valid_accuracy:.4f}\")\n",
    "        \n",
    "        # Save the loss values for plotting\n",
    "        train_loss_history.append(train_loss/len(train_loader))\n",
    "        valid_loss_history.append(valid_loss/len(valid_loader))\n",
    "\n",
    "    return model, train_loss_history, valid_loss_history\n",
    "\n",
    "\n",
    "model = CNN_EncoderDecoder()\n",
    "model, train_loss_history, valid_loss_history = train(model, train_loader, valid_loader, num_epochs=2, learning_rate=0.001)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "base_dir = '/home/csalitre/school/ecgr-5106/final-project/'\n",
    "torch.save(model.state_dict(), os.path.join(base_dir, 'cnn_encoderdecoder.pth'))\n",
    "\n",
    "# Load the trained model\n",
    "model_path = os.path.join(base_dir, 'cnn_encoderdecoder.pth')\n",
    "model = CNN_EncoderDecoder()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = os.path.join(base_dir, \"semantic-segmentation/test2/images/27_jpg.rf.b2a2b9811786cc32a23c46c560f04d07.jpg\")\n",
    "image = Image.open(image_path).convert(\"L\")\n",
    "input_image = image_transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "\n",
    "# Convert output tensor to numpy array\n",
    "output_np = output.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "# In[2]\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the input image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Input Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the segmentation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(output_np[0], cmap='gray')\n",
    "plt.title('Segmentation Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
